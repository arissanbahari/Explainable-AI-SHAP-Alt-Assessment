# Explainable AI - Using SHAP to explain heart disease predictions

## Background

One of the courses I took during my master's was WQF7009 Explainable Artificial Intelligence @ Universiti Malaya. Explainable AI (XAI) is concerned with understanding why AI models make the decisions they do. It's not enough to run a model that predicts whether someone gets heart disease. We must also understand _why_ the model made that prediction. Which factors/ variables contributed the most to that prediction?

Using XAI, models are more transparent and understandable, leading to trust and confidence in an AI model's prediction.

## Project Brief

For my alternative assessment, we were required to build a model that predicts heart disease and a relevant XAI model to assess the predictions. We were then tasked to answer the questions from the brief. I chose to go with a Random Forest classifier and SHAP Explainer as my XAI model.

## Assets

| Asset | Description |
| --- | --- |
| Explainable_heart_disease_prediction.ipynb | Notebook that built the RF model and SHAP explainer |
| Report_explainable_heart_disease.pdf | Report writeup for the notebook with further explanations |
| Training_set_heart.csv | Training dataset |
| Testing_set_heart.csv | Testing dataset |

## Additional Information

**Tools**
- Python for EDA, building RF model and SHAP explainer XAI model
- Microsoft word for the report writeup

**Dataset**

- Dataset is attached, containing the training and testing datasets.
  
